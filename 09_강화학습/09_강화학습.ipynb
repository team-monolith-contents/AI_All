{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"-C2lKQoVuBHo"},"source":["# **[9] 강화학습**\n","\n","**[학습 목표]**\n","1. 강화학습의 학습 원리를 이해할 수 있다.\n","2. 강화학습이 사용되는 다양한 사례를 탐색할 수 있다.\n","3. 강화학습을 이용하여 실제 게임을 학습시킬 수 있다."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NaRPgHqz-TCk"},"source":[" 👉 오늘의 실습은 학습에 **매우 긴 시간**(30분 이상)이 걸려요.  \n","수업을 진행하기 전 미리 2-(2) 코드를 실행하는 것을 추천드려요!"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2-PfUmkV5nKP"},"source":["## **1. 강화학습**  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2sJRHyaQ-TCl"},"source":["### **(1) 강화학습의 원리**  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OPQhJ4HYuBHu"},"source":["강화학습은 **시행착오**를 통해 주어진 상태에서 최적의 행동을 선택하는 학습 방법이에요.  \n","강화학습에서는 지도/비지도 기계학습과 달리, 아무런 데이터가 주어지지 않아요.  \n","대신 주어진 상태에서 행동의 결과에 대한 **보상**을 에이전트에게 주어요.   \n","에이전트는 행동과 보상에 대한 정보를 바탕으로, 어떤 행동을 취해야 가장 큰 보상을 가져올지 스스로 학습하는 것이지요."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"O3kZwpNLuBHu"},"source":["게임을 하는 사람이 게임 실력을 키우는 과정을 통해, 강화 학습의 원리를 자세하게 이해해보아요.\n","\n","<table>\n","<tr>\n","    <th><img src=\"https://drive.google.com/uc?id=1VLIg1Yf-Rw_G6yrf0Tj-aDfE5oNEj-6F\" width=\"750\"></th>\n","    </tr>\n","<tr>\n","    <th>강화학습의 원리</th>\n","</tr>\n","</table>  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kkMfDlFJuBHu"},"source":["에이전트는 둘러싸고 있는 환경과 상호작용하는 행동의 주체를 의미해요.  \n","환경은 에이전트를 둘러싸고 있는 것들이에요.  \n","상태는 에이전트에 대한 상태를 숫자로 표현한 것이에요.  \n","행동은 에이전트가 실제 행동한 내용이에요.  \n","보상은 에이전트가 행동한 결과로 받게 되는 것이에요.  \n","정책은 행동에 따른 보상을 기반으로 에이전트가 행동하는 방향이에요.  \n"," \n","> 에이전트는 게임이라는 환경에서, 어떻게 행동해야 더 많은 보상을 얻을지 학습해요.   \n","> 학습을 통해, 에이전트는 더 많은 보상을 얻기 위한 정책을 수립하는 것이지요."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8A_kco9o-TCm"},"source":["**[문제1] 위의 그림에서 강화학습의 각 요소는 무엇에 해당되는지 작성해보아요.** "]},{"cell_type":"raw","metadata":{"id":"iiew-7DE-TCm"},"source":[" 👉 \n"," 👉 "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"T95F0kWMuBHv"},"source":["### **(2) 강화학습의 생활 속 사례**  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"uTPyEUeTuBHv"},"source":["강화학습은 실제 생활 속에서 다양하게 사용될 수 있어요.  \n","아래 두 가지 예시를 소개하지만, 그 외의 다른 예시들도 유튜버 \"생활코딩\"님께서 정리하신 \n","<a href=\"https://docs.google.com/spreadsheets/d/1TnRTcrA7yapqfnXCm_M6ZURD7ofLbH62mZIjznwEOKI/edit#gid=414903589\">링크</a>\n","를 통해 확인할 수 있어요.  \n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Nwp9BpAtuBHv"},"source":["예시 1: 인공지능 골키퍼가 상대 선수의 축구공을 막는다.  \n","<a href=\"https://youtu.be/7Yc6ZHixgRk\">동영상 링크</a>\n","\n","- 에이전트 : 골키퍼\n","- 환경 : 축구장\n","- 행동 : 상대가 찬 공을 막기 위해 적절한 위치로 이동한다.\n","- 보상 : 상대가 찬 공이 골대에 들어가지 않으면 득점을 막을 수 있다.\n","- 상태 : 상대가 차는 축구공을 막기 위한 골대의 골키퍼"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"X4WRR0JYuBHw"},"source":["예시 2: 강화학습을 통해 볼링공이 볼링을 맞춥니다.  \n","<a href=\"https://www.youtube.com/watch?v=nReMgotclXU\">동영상 링크</a>\n","\n","- 에이전트 : 볼링공\n","- 환경 : 볼링장\n","- 행동 : 볼링공의 위치, 스핀을 달리하여 굴리기\n","- 보상 : 볼링핀을 시간 내에 맞추면 상을 준다. 못 맞히거나 시간을 초과하면 벌을 준다.\n","- 상태 : 볼링공과 볼링핀의 거리, 볼링공의 위치"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"q8_OIzBpuBHw"},"source":["## **2. 강화학습 실습**  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"7mDLmcfgYSjf"},"source":["### **(1) CartPole 플레이**  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["우선 CartPole이 어떤 게임인지 알아야겠죠?  \n","말 그대로 Cart를 움직여 Pole이 떨어지지 않게 하는 게임이에요.    \n","직접 플레이해보고 최고점을 누가 기록했는지 대결해보아요!  \n","\n","<a href=\"https://jeffjar.me/cartpole.html\">게임 플레이</a>\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### **(2) CartPole 학습**  \n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["CartPole은 강화학습을 사용하여 훈련시킬 수 있는 대표적인 게임 중 하나에요.  \n","저희가 제공하는 강화학습 모델을 사용하여 학습이 이루어지는 과정을 관찰해보아요."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27249,"status":"ok","timestamp":1685472274131,"user":{"displayName":"성무열","userId":"14501712316857642086"},"user_tz":-540},"id":"iX-uHzTHuBHw","outputId":"14b1eb79-bb6d-42ca-df77-b4f3a699b6c1"},"outputs":[],"source":["!sudo apt install xvfb\n","\n","!pip install gym\n","!pip install gym-notebook-wrapper"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"executionInfo":{"elapsed":652,"status":"error","timestamp":1685472274780,"user":{"displayName":"성무열","userId":"14501712316857642086"},"user_tz":-540},"id":"4fobS01quBHy","outputId":"a1d3b259-42b7-43ef-f414-dc204106a527"},"outputs":[],"source":["import gym\n","import gnwrapper\n","import time\n","import matplotlib.pyplot as plt\n","\n","# model.py가 기존 path 내에 있도록 설정\n","from model import DQNAgent"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"aborted","timestamp":1685472274781,"user":{"displayName":"성무열","userId":"14501712316857642086"},"user_tz":-540},"id":"DrZX58N4L6WZ"},"outputs":[],"source":["env = gnwrapper.Animation(gym.make('CartPole-v1'))\n","state_size = env.observation_space.shape[0]\n","action_size = env.action_space.n\n","\n","agent = DQNAgent(state_size, action_size)\n","\n","scores, episodes = [], []\n","counts = []\n","score_avg = 0\n","\n","num_episode = 100"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1685472274781,"user":{"displayName":"성무열","userId":"14501712316857642086"},"user_tz":-540},"id":"9JnHorF2KEdM"},"outputs":[],"source":["for e in range(num_episode):\n","    done = False\n","    score = 0\n","\n","    state = env.reset()\n","    state = state.reshape(1, -1)\n","    count = 0\n","\n","    while not done:\n","        env.render()\n","\n","        action = agent.choose_action(state)\n","\n","        next_state, reward, done, info = env.step(action)\n","        next_state = next_state.reshape(1, -1)\n","\n","        score += reward\n","        reward = 0.1 if not done or score == 500 else -1\n","\n","        agent.remember(state, action, reward, next_state, done)\n","\n","        if len(agent.memory) >= agent.train_start:\n","            agent.train_model()\n","\n","        state = next_state\n","        count += 1\n","\n","        if done:\n","            agent.update_target_model()\n","\n","            score_avg = 0.9 * score_avg + 0.1 * score if score_avg != 0 else score\n","            print(\"Episode finished after {} timesteps\".format(count+1))\n","            print('episode: {:3d} | score avg {:3.2f} | memory length: {:4d} | epsilon: {:.4f}'.format(e, score_avg, len(agent.memory), agent.epsilon))\n","\n","            scores.append(score_avg)\n","            episodes.append(e)\n","            counts.append(count)\n","\n","            time.sleep(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":467},"executionInfo":{"elapsed":1098,"status":"ok","timestamp":1681570077803,"user":{"displayName":"성무열","userId":"14501712316857642086"},"user_tz":-540},"id":"Fz9IvwauMICg","outputId":"cb990a2b-d802-4c68-8c2b-032a118318fc"},"outputs":[],"source":["plt.plot(episodes, scores, 'blue')\n","plt.plot(episodes, counts, 'green')\n","plt.xlabel('episode')\n","plt.ylabel('average score, timesteps')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"kaggle","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"8c352b738e5f22da9f29eb9cb9994f25c5223ab3395af3650b8321ab644afce4"}}},"nbformat":4,"nbformat_minor":0}
